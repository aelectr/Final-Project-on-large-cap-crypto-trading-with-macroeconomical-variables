{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d17d515f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zipline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2584\\710800811.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscatter_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mzipline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtalib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'zipline'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import zipline\n",
    "import pandas as pd\n",
    "import talib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, classification_report\n",
    "from pandas_datareader import data\n",
    "import csv\n",
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea491925",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2584\\3873057858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BitstampData.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('BitstampData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbeb56d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2584\\1105136813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# peek at data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.shape\n",
    "# peek at data\n",
    "set_option('display.width', 100)\n",
    "dataset.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66bfc4ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2584\\2015224217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create short simple moving average over the short window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m dataset['short_mavg'] = dataset['Close'].rolling(window=10, min_periods=1,\\\n\u001b[0m\u001b[0;32m      3\u001b[0m center=False).mean()\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create long simple moving average over the long window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m dataset['long_mavg'] = dataset['Close'].rolling(window=60, min_periods=1,\\\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Create short simple moving average over the short window\n",
    "dataset['short_mavg'] = dataset['Close'].rolling(window=10, min_periods=1,\\\n",
    "center=False).mean()\n",
    "# Create long simple moving average over the long window\n",
    "dataset['long_mavg'] = dataset['Close'].rolling(window=60, min_periods=1,\\\n",
    "center=False).mean()\n",
    "# Create signals\n",
    "dataset['signal'] = np.where(dataset['short_mavg'] >\n",
    "dataset['long_mavg'], 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e02897",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-855d65d69724>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-855d65d69724>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    EMA = pd.Series(df['Close'].ewm(span=n, min_periods=n).mean(), name='EMA_'\\\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#calculation of exponential moving average\n",
    "def EMA(df, n):\n",
    "EMA = pd.Series(df['Close'].ewm(span=n, min_periods=n).mean(), name='EMA_'\\\n",
    "+ str(n))\n",
    "return EMA\n",
    "dataset['EMA10'] = EMA(dataset, 10)\n",
    "dataset['EMA30'] = EMA(dataset, 30)\n",
    "dataset['EMA200'] = EMA(dataset, 200)\n",
    "dataset.head()\n",
    "\n",
    "#calculation of rate of change\n",
    "def ROC(df, n):\n",
    "M = df.diff(n - 1)\n",
    "N = df.shift(n - 1)\n",
    "ROC = pd.Series(((M / N) * 100), name = 'ROC_' + str(n))\n",
    "return ROC\n",
    "dataset['ROC10'] = ROC(dataset['Close'], 10)\n",
    "dataset['ROC30'] = ROC(dataset['Close'], 30)\n",
    "\n",
    "#calculation of price momentum\n",
    "def MOM(df, n):\n",
    "MOM = pd.Series(df.diff(n), name='Momentum_' + str(n))\n",
    "return MOM\n",
    "dataset['MOM10'] = MOM(dataset['Close'], 10)\n",
    "dataset['MOM30'] = MOM(dataset['Close'], 30)\n",
    "\n",
    "#calculation of relative strength index\n",
    "def RSI(series, period):\n",
    "delta = series.diff().dropna()\n",
    "u = delta * 0\n",
    "d = u.copy()\n",
    "u[delta > 0] = delta[delta > 0]\n",
    "d[delta < 0] = -delta[delta < 0]\n",
    "u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "u = u.drop(u.index[:(period-1)])\n",
    "d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "d = d.drop(d.index[:(period-1)])\n",
    "rs = u.ewm(com=period-1, adjust=False).mean() / \\\n",
    "d.ewm(com=period-1, adjust=False).mean()\n",
    "return 100 - 100 / (1 + rs)\n",
    "dataset['RSI10'] = RSI(dataset['Close'], 10)\n",
    "dataset['RSI30'] = RSI(dataset['Close'], 30)\n",
    "dataset['RSI200'] = RSI(dataset['Close'], 200)\n",
    "\n",
    "#calculation of stochastic osillator.\n",
    "Case Study 3: Bitcoin Trading Strategy | 183\n",
    "def STOK(close, low, high, n):\n",
    "STOK = ((close - low.rolling(n).min()) / (high.rolling(n).max() - \\\n",
    "low.rolling(n).min())) * 100\n",
    "return STOK\n",
    "def STOD(close, low, high, n):\n",
    "STOK = ((close - low.rolling(n).min()) / (high.rolling(n).max() - \\\n",
    "low.rolling(n).min())) * 100\n",
    "STOD = STOK.rolling(3).mean()\n",
    "return STOD\n",
    "dataset['%K10'] = STOK(dataset['Close'], dataset['Low'], dataset['High'], 10)\n",
    "dataset['%D10'] = STOD(dataset['Close'], dataset['Low'], dataset['High'], 10)\n",
    "dataset['%K30'] = STOK(dataset['Close'], dataset['Low'], dataset['High'], 30)\n",
    "dataset['%D30'] = STOD(dataset['Close'], dataset['Low'], dataset['High'], 30)\n",
    "dataset['%K200'] = STOK(dataset['Close'], dataset['Low'], dataset['High'], 200)\n",
    "dataset['%D200'] = STOD(dataset['Close'], dataset['Low'], dataset['High'], 200)\n",
    "\n",
    "#calculation of moving average\n",
    "def MA(df, n):\n",
    "MA = pd.Series(df['Close'].rolling(n, min_periods=n).mean(), name='MA_'\\\n",
    "+ str(n))\n",
    "return MA\n",
    "dataset['MA21'] = MA(dataset, 10)\n",
    "dataset['MA63'] = MA(dataset, 30)\n",
    "dataset['MA252'] = MA(dataset, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['Weighted_Price']].plot(grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot = dataset.groupby(['signal']).size().plot(kind='barh', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d56755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out validation dataset for the end\n",
    "subset_dataset= dataset.iloc[-100000:]\n",
    "Y= subset_dataset[\"signal\"]\n",
    "X = subset_dataset.loc[:, dataset.columns != 'signal']\n",
    "validation_size = 0.2\n",
    "seed = 1\n",
    "X_train, X_validation, Y_train, Y_validation =\\\n",
    "train_test_split(X, Y, test_size=validation_size, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc20753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test options for classification\n",
    "num_folds = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(n_jobs=-1)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "#Neural Network\n",
    "models.append(('NN', MLPClassifier()))\n",
    "# Ensemble Models\n",
    "# Boosting methods\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "models.append(('RF', RandomForestClassifier(n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [20,80]\n",
    "max_depth= [5,10]\n",
    "criterion = [\"gini\",\"entropy\"]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth, \\\n",
    "criterion = criterion )\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, \\\n",
    "scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\\\n",
    "grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = RandomForestClassifier(criterion='gini', n_estimators=80,max_depth=10)\n",
    "#model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "# estimate accuracy on validation set\n",
    "predictions = model.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff96944",
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance = pd.DataFrame({'Importance':model.feature_importances_*100},\\\n",
    "index=X.columns)\n",
    "Importance.sort_values('Importance', axis=0, ascending=True).plot(kind='barh', \\\n",
    "color='r' )\n",
    "plt.xlabel('Variable Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtestdata = pd.DataFrame(index=X_validation.index)\n",
    "backtestdata['signal_pred'] = predictions\n",
    "backtestdata['signal_actual'] = Y_validation\n",
    "backtestdata['Market Returns'] = X_validation['Close'].pct_change()\n",
    "backtestdata['Actual Returns'] = backtestdata['Market Returns'] *\\\n",
    "backtestdata['signal_actual'].shift(1)\n",
    "backtestdata['Strategy Returns'] = backtestdata['Market Returns'] * \\\n",
    "backtestdata['signal_pred'].shift(1)\n",
    "backtestdata=backtestdata.reset_index()\n",
    "backtestdata.head()\n",
    "backtestdata[['Strategy Returns','Actual Returns']].cumsum().hist()\n",
    "backtestdata[['Strategy Returns','Actual Returns']].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ce9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
